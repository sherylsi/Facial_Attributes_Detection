{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0nEcnN4MweC"
   },
   "source": [
    "# Facial Attributes Classifier Models\n",
    "\n",
    "In this file I classify images of specific facial att. and will use **transfer learning** to improve results.\n",
    "\n",
    "**Note:** It is recommended to run this file on **Google Colab** with GPU acceleration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file contain functions for: \n",
    "- Data Preparation\n",
    "    * preprocess image\n",
    "    * split train test for\n",
    "        * Positive Class - 1\n",
    "        * Negative Class - 0\n",
    "    * Create Labeled DF for train and test (file_id, label, image)\n",
    "    \n",
    "- Apply ImageDataGenerator class\n",
    "    * Train Set\n",
    "    * Validation Set\n",
    "    * Test Set\n",
    "    \n",
    "- Modeling using DeepFace assemble or standalone of: \n",
    "    \n",
    "    * 'vgg_face': VGGFace,\n",
    "    * 'open_face': OpenFace,\n",
    "    * 'facenet': Facenet,\n",
    "    * 'deep_face': FbDeepFace,\n",
    "    * 'deep_id': DeepID,\n",
    "    * \"emotion\": Emotion,\n",
    "    * \"age\": Age,\n",
    "    * \"gender\": Gender,\n",
    "    * \"race\": Race\n",
    "      \n",
    "    - Transfer Learning with:\n",
    "        * Callback\n",
    "        * Optimzing\n",
    "        * Fitting\n",
    "        * Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "veZjl0m4U3PQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from varname import nameof\n",
    "import shutil \n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from google.colab import drive\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "np.set_printoptions(precision=2)\n",
    "# pd.options.display.max_seq_items = 20\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 15),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Input, Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow import optimizers\n",
    "import tensorboard\n",
    "from sklearn.metrics import classification_report\n",
    "#facial analysis\n",
    "from deepface.extendedmodels import Age, Gender, Race, Emotion\n",
    "from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace, DeepID\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1599833164676,
     "user": {
      "displayName": "Tal T",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi2JEqenXMt8KQ0yJDTMq6jL2fP9wTV8ULQdEoZaw=s64",
      "userId": "04492565207152809606"
     },
     "user_tz": -180
    },
    "id": "YXKuO394Rm_O",
    "outputId": "22b37248-b17f-4a5b-aaa3-193bde217366"
   },
   "source": [
    "### Constant path for Colab or Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_imagepath(file):\n",
    "    \"\"\"\n",
    "    function look for image files in the relevant directory determine by condition\n",
    "    param: file - str name of image file\n",
    "    return: relevent file path\n",
    "    \"\"\"\n",
    "    temp_file = int(file.split('.')[0][-6:])\n",
    "    if temp_file <= 70000:\n",
    "        IMAGEPATH = '/Users/tal/Google Drive/Cellebrite/Datasets/face_att/1/'\n",
    "    elif temp_file > 70000 and temp_file < 140000:\n",
    "        IMAGEPATH = '/Users/tal/Google Drive/Cellebrite/Datasets/face_att/2/'\n",
    "    elif temp_file >= 140000:\n",
    "        IMAGEPATH = '/Users/tal/Google Drive/Cellebrite/Datasets/face_att/3/'\n",
    "    else:\n",
    "        IMAGEPATH = '/Users/tal/Google Drive/Cellebrite/Datasets/face_att/'\n",
    "    return os.path.join(IMAGEPATH, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "L3e7h8C_UkXD"
   },
   "outputs": [],
   "source": [
    "if os.getcwd() != '/content':\n",
    "    IMAGEPATH = '/Users/tal/Google Drive/Cellebrite/Datasets/face_att/'\n",
    "    IND_FILE = '/Users/tal/Google Drive/Cellebrite/files list.csv'\n",
    "    try:\n",
    "        FACEPATH = os.path.join(IMAGEPATH,'face_att')\n",
    "    except:\n",
    "        FACEPATH = find_imagepath(file)\n",
    "else:\n",
    "    drive.mount('/content/drive')\n",
    "    IND_FILE = '/content/drive/My Drive/Cellebrite/files list.csv'\n",
    "    IMAGEPATH = '/content/drive/My Drive/Cellebrite/Datasets'\n",
    "    FACEPATH = os.path.join(IMAGEPATH,'face_att')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5MeVhSAOYW2"
   },
   "source": [
    "# Data Preparation\n",
    "Data splited to sets for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocess(data, img_size):\n",
    "    data_img = []\n",
    "    IMG_WIDTH = img_size\n",
    "    IMG_HEIGHT = img_size\n",
    "    for i in data.iloc[:, 0]:\n",
    "        image = cv2.imread(find_imagepath(i))\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.cv2.CAP_OPENNI_GRAY_IMAGE)\n",
    "        image = np.array(image).astype('float32') / 255.\n",
    "        data_img.append(image)\n",
    "    return data_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wearing_Earrings',\n",
       " 'Wearing_Hat',\n",
       " 'Wearing_Lipstick',\n",
       " 'Wearing_Necklace',\n",
       " 'Wearing_Necktie',\n",
       " 'Black_Hair',\n",
       " 'Blond_Hair',\n",
       " 'Brown_Hair',\n",
       " 'Gray_Hair',\n",
       " 'Receding_Hairline',\n",
       " 'Straight_Hair',\n",
       " 'Wavy_Hair']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(IND_FILE)\n",
    "cols = df.columns.tolist()\n",
    "accessories_label = [l for l in cols if l.startswith(\"Wearing\")]\n",
    "hair_label = [l for l in cols if \"Hair\" in l and not l.startswith('0')]\n",
    "labels = [*accessories_label, *hair_label]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def data_preprocess(index_file, labels, balance, binary, img_size=224):\n",
    "        \"\"\"\n",
    "        function read \"files list.csv\" and return train test filename and pixel represtation for the called label\n",
    "        params: index_file - CSV for indexed labels\n",
    "                labels - list of labels from csv columns name\n",
    "                balance - int for a specific balanced set size\n",
    "                binary - bool if user want also the negative class (= 0_  +  labels)\n",
    "        returns: balanced train test set for positive and negative or multiclass labels\n",
    "        \"\"\"\n",
    "        # read labels file list\n",
    "        if isinstance(labels, str):\n",
    "            df = pd.read_csv(index_file, usecols=[labels])\n",
    "        else:\n",
    "            df = pd.read_csv(index_file, usecols=labels)\n",
    "            l = len(labels)\n",
    "            class_label = {k:v for k,v in zip(range(1, l+1), labels)}\n",
    "            print(df.)\n",
    "            print(label_class)\n",
    "        df_label = df[(df[labels] != 0) & (df[labels] != '0')]\n",
    "        if len(df_label) < balance:\n",
    "            print(f'The number of sample ({balance}) you asked for the label {labels} is higher than the number of '\n",
    "                  f'sample available {len(df_label)}\\nProcess Continue with {len(df_label)} Images')\n",
    "            balance = len(df_label)\n",
    "\n",
    "        # Get the label folder if not provide or label files are mix in the same folder\n",
    "        #     folder = df_label[labels].apply(lambda x: '_'.join(str(x).split('_')[:-1])).unique()\n",
    "        #     folder = [f for f in folder if f]\n",
    "\n",
    "        # Train Test Split\n",
    "        if balance is None:\n",
    "            train_size = int(len(df_label) * 0.8)\n",
    "        else:\n",
    "            train_size = int(balance * 0.8)  # int(input('Please enter 2nd class train size: '))\n",
    "\n",
    "        train = df_label[:train_size]\n",
    "        test = df_label[train_size:balance]\n",
    "\n",
    "        print(f\"Starting Image Preprocessing\")\n",
    "        # Preprocess train image\n",
    "        if binary:\n",
    "            class_label = [np.zeros(len(train)) if labels[0].isdigit() else np.ones(len(train))]            \n",
    "        train_img = img_preprocess(train, img_size)\n",
    "        train = pd.DataFrame({'files': train.iloc[:, 0], 'label': np.array(*class_label).astype(str), 'image': pd.Series(train_img)})\n",
    "\n",
    "        # Preprocess test image\n",
    "        if binary:\n",
    "            class_label = [np.zeros(len(test)) if labels[0].isdigit() else np.ones(len(test))]\n",
    "        test_img = img_preprocess(test, img_size)\n",
    "        test = pd.DataFrame({'files': test.iloc[:, 0], 'label': np.array(*class_label).astype(str), 'image': test_img})\n",
    "        print('Done!')\n",
    "\n",
    "        if binary:\n",
    "            print('Creating Negative Class')\n",
    "            # check for balanced data\n",
    "            try:\n",
    "                assert pd.read_csv(index_file, usecols=['0_' + labels]).shape[0] <= balance\n",
    "            except AssertionError:\n",
    "                print(f\"Negative class files:\\t {pd.read_csv(index_file, usecols=['0_' + labels]).shape[0]}\")\n",
    "\n",
    "            # Add Negative class\n",
    "            train_n, test_n = data_preprocess(index_file, '0_' + labels, balance, binary=False)\n",
    "            train = pd.concat([train, train_n], axis=0)\n",
    "            test = pd.concat([test, test_n], axis=0)\n",
    "            print('Shape with Negative class:')\n",
    "        print(f'Train shape: \\t{np.array(train).shape}\\nTest shape: \\t{np.array(test).shape}')\n",
    "\n",
    "        # Verification\n",
    "        try:\n",
    "            assert test['files'].nunique() == len(test)\n",
    "            assert train['files'].nunique() == len(train)\n",
    "            print(\"Assertions Passed! Sets are image files W/O duplication\")\n",
    "        except AssertionError:\n",
    "            print(\"Assertions Failed\")\n",
    "\n",
    "#         train = shuffle(train)\n",
    "#         test = shuffle(test)\n",
    "\n",
    "        return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Wearing_Earrings          Wearing_Hat     Wearing_Lipstick  \\\n",
      "0       face_att_000001.jpg  face_att_000037.jpg  face_att_000001.jpg   \n",
      "1       face_att_000004.jpg  face_att_000068.jpg  face_att_000004.jpg   \n",
      "2       face_att_000006.jpg  face_att_000074.jpg  face_att_000005.jpg   \n",
      "3       face_att_000009.jpg  face_att_000095.jpg  face_att_000006.jpg   \n",
      "4       face_att_000018.jpg  face_att_000137.jpg  face_att_000009.jpg   \n",
      "5       face_att_000024.jpg  face_att_000138.jpg  face_att_000010.jpg   \n",
      "6       face_att_000029.jpg  face_att_000149.jpg  face_att_000014.jpg   \n",
      "7       face_att_000039.jpg  face_att_000154.jpg  face_att_000018.jpg   \n",
      "8       face_att_000040.jpg  face_att_000166.jpg  face_att_000019.jpg   \n",
      "9       face_att_000042.jpg  face_att_000195.jpg  face_att_000022.jpg   \n",
      "10      face_att_000043.jpg  face_att_000196.jpg  face_att_000024.jpg   \n",
      "11      face_att_000045.jpg  face_att_000199.jpg  face_att_000026.jpg   \n",
      "12      face_att_000047.jpg  face_att_000210.jpg  face_att_000027.jpg   \n",
      "13      face_att_000057.jpg  face_att_000243.jpg  face_att_000028.jpg   \n",
      "14      face_att_000066.jpg  face_att_000308.jpg  face_att_000029.jpg   \n",
      "15      face_att_000071.jpg  face_att_000314.jpg  face_att_000034.jpg   \n",
      "16      face_att_000074.jpg  face_att_000333.jpg  face_att_000035.jpg   \n",
      "17      face_att_000083.jpg  face_att_000335.jpg  face_att_000039.jpg   \n",
      "18      face_att_000084.jpg  face_att_000348.jpg  face_att_000040.jpg   \n",
      "19      face_att_000085.jpg  face_att_000366.jpg  face_att_000042.jpg   \n",
      "20      face_att_000095.jpg  face_att_000400.jpg  face_att_000043.jpg   \n",
      "21      face_att_000106.jpg  face_att_000403.jpg  face_att_000044.jpg   \n",
      "22      face_att_000108.jpg  face_att_000408.jpg  face_att_000045.jpg   \n",
      "23      face_att_000111.jpg  face_att_000416.jpg  face_att_000046.jpg   \n",
      "24      face_att_000117.jpg  face_att_000453.jpg  face_att_000047.jpg   \n",
      "25      face_att_000122.jpg  face_att_000465.jpg  face_att_000054.jpg   \n",
      "26      face_att_000124.jpg  face_att_000496.jpg  face_att_000056.jpg   \n",
      "27      face_att_000132.jpg  face_att_000501.jpg  face_att_000057.jpg   \n",
      "28      face_att_000133.jpg  face_att_000581.jpg  face_att_000058.jpg   \n",
      "29      face_att_000148.jpg  face_att_000635.jpg  face_att_000059.jpg   \n",
      "...                     ...                  ...                  ...   \n",
      "198022                    0                    0                    0   \n",
      "198023                    0                    0                    0   \n",
      "198024                    0                    0                    0   \n",
      "198025                    0                    0                    0   \n",
      "198026                    0                    0                    0   \n",
      "198027                    0                    0                    0   \n",
      "198028                    0                    0                    0   \n",
      "198029                    0                    0                    0   \n",
      "198030                    0                    0                    0   \n",
      "198031                    0                    0                    0   \n",
      "198032                    0                    0                    0   \n",
      "198033                    0                    0                    0   \n",
      "198034                    0                    0                    0   \n",
      "198035                    0                    0                    0   \n",
      "198036                    0                    0                    0   \n",
      "198037                    0                    0                    0   \n",
      "198038                    0                    0                    0   \n",
      "198039                    0                    0                    0   \n",
      "198040                    0                    0                    0   \n",
      "198041                    0                    0                    0   \n",
      "198042                    0                    0                    0   \n",
      "198043                    0                    0                    0   \n",
      "198044                    0                    0                    0   \n",
      "198045                    0                    0                    0   \n",
      "198046                    0                    0                    0   \n",
      "198047                    0                    0                    0   \n",
      "198048                    0                    0                    0   \n",
      "198049                    0                    0                    0   \n",
      "198050                    0                    0                    0   \n",
      "198051                    0                    0                    0   \n",
      "\n",
      "           Wearing_Necklace      Wearing_Necktie  \n",
      "0       face_att_000004.jpg  face_att_000015.jpg  \n",
      "1       face_att_000014.jpg  face_att_000021.jpg  \n",
      "2       face_att_000018.jpg  face_att_000032.jpg  \n",
      "3       face_att_000019.jpg  face_att_000055.jpg  \n",
      "4       face_att_000022.jpg  face_att_000072.jpg  \n",
      "5       face_att_000024.jpg  face_att_000080.jpg  \n",
      "6       face_att_000044.jpg  face_att_000091.jpg  \n",
      "7       face_att_000054.jpg  face_att_000104.jpg  \n",
      "8       face_att_000062.jpg  face_att_000109.jpg  \n",
      "9       face_att_000066.jpg  face_att_000116.jpg  \n",
      "10      face_att_000083.jpg  face_att_000125.jpg  \n",
      "11      face_att_000085.jpg  face_att_000127.jpg  \n",
      "12      face_att_000086.jpg  face_att_000129.jpg  \n",
      "13      face_att_000087.jpg  face_att_000130.jpg  \n",
      "14      face_att_000093.jpg  face_att_000135.jpg  \n",
      "15      face_att_000094.jpg  face_att_000143.jpg  \n",
      "16      face_att_000103.jpg  face_att_000152.jpg  \n",
      "17      face_att_000106.jpg  face_att_000153.jpg  \n",
      "18      face_att_000107.jpg  face_att_000164.jpg  \n",
      "19      face_att_000110.jpg  face_att_000171.jpg  \n",
      "20      face_att_000131.jpg  face_att_000197.jpg  \n",
      "21      face_att_000155.jpg  face_att_000209.jpg  \n",
      "22      face_att_000161.jpg  face_att_000221.jpg  \n",
      "23      face_att_000167.jpg  face_att_000264.jpg  \n",
      "24      face_att_000168.jpg  face_att_000297.jpg  \n",
      "25      face_att_000172.jpg  face_att_000306.jpg  \n",
      "26      face_att_000174.jpg  face_att_000307.jpg  \n",
      "27      face_att_000181.jpg  face_att_000313.jpg  \n",
      "28      face_att_000184.jpg  face_att_000318.jpg  \n",
      "29      face_att_000189.jpg  face_att_000321.jpg  \n",
      "...                     ...                  ...  \n",
      "198022                    0                    0  \n",
      "198023                    0                    0  \n",
      "198024                    0                    0  \n",
      "198025                    0                    0  \n",
      "198026                    0                    0  \n",
      "198027                    0                    0  \n",
      "198028                    0                    0  \n",
      "198029                    0                    0  \n",
      "198030                    0                    0  \n",
      "198031                    0                    0  \n",
      "198032                    0                    0  \n",
      "198033                    0                    0  \n",
      "198034                    0                    0  \n",
      "198035                    0                    0  \n",
      "198036                    0                    0  \n",
      "198037                    0                    0  \n",
      "198038                    0                    0  \n",
      "198039                    0                    0  \n",
      "198040                    0                    0  \n",
      "198041                    0                    0  \n",
      "198042                    0                    0  \n",
      "198043                    0                    0  \n",
      "198044                    0                    0  \n",
      "198045                    0                    0  \n",
      "198046                    0                    0  \n",
      "198047                    0                    0  \n",
      "198048                    0                    0  \n",
      "198049                    0                    0  \n",
      "198050                    0                    0  \n",
      "198051                    0                    0  \n",
      "\n",
      "[198052 rows x 5 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-6223c560b519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# label = ['Wearing']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIND_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessories_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-14ae224bbaf0>\u001b[0m in \u001b[0;36mdata_preprocess\u001b[0;34m(index_file, labels, balance, binary, img_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mclass_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdf_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbalance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_class' is not defined"
     ]
    }
   ],
   "source": [
    "# label = ['Wearing']\n",
    "train, test = data_preprocess(IND_FILE, accessories_label, 5000, False, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face_att_000001.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.9137255, 0.9137255, 0.9137255, 0.9137255, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face_att_000004.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.1882353, 0.3529412, 0.3764706, 0.34509805,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face_att_000006.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face_att_000009.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.3019608, 0.29803923, 0.29803923, 0.2980392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face_att_000018.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.83137256, 0.83137256, 0.83137256, 0.831372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>face_att_000024.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.47058824, 0.47058824, 0.47058824, 0.470588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>face_att_000029.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.4, 0.38431373, 0.38039216, 0.38039216, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>face_att_000039.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.74509805, 0.75686276, 0.77254903, 0.796078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>face_att_000040.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.12941177, 0.12941177, 0.12941177, 0.133333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face_att_000042.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.20392157, 0.20784314, 0.20784314, 0.196078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>face_att_000043.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.6901961, 0.6901961, 0.6901961, 0.6901961, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>face_att_000045.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.76862746, 0.7921569, 0.8, 0.8039216, 0.807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>face_att_000047.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.8117647, 0.79607844, 0.7921569, 0.79607844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>face_att_000057.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.83137256, 0.827451, 0.827451, 0.8235294, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>face_att_000066.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.4509804, 0.45490196, 0.45490196, 0.4549019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>face_att_000071.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.4745098, 0.47058824, 0.46666667, 0.4627451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>face_att_000074.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.93333334, 0.93333334, 0.93333334, 0.933333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>face_att_000083.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.6509804, 0.654902, 0.65882355, 0.6627451, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>face_att_000084.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.23137255, 0.22352941, 0.21176471, 0.203921...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>face_att_000085.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.54509807, 0.54509807, 0.54509807, 0.545098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>face_att_000095.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.16470589, 0.16470589, 0.16470589, 0.164705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>face_att_000106.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.003921569, 0.003921569, 0.003921569, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>face_att_000108.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.28627452, 0.29803923, 0.29803923, 0.290196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>face_att_000111.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.99607843, 0.99607843, 0.99607843, 0.996078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>face_att_000117.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.8235294, 0.827451, 0.8666667, 0.9098039, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>face_att_000122.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.23529412, 0.23137255, 0.23137255, 0.231372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>face_att_000124.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.76862746, 0.77254903, 0.77254903, 0.776470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>face_att_000132.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.9607843, 0.9607843, 0.9607843, 0.9607843, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>face_att_000133.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.22352941, 0.21568628, 0.20784314, 0.223529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>face_att_000148.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.1254902, 0.1254902, 0.1254902, 0.1254902, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>face_att_021171.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.99607843, 0.99607843, 0.99607843, 0.996078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>face_att_021175.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.003921569, 0.003921569, 0.003921569, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>face_att_021179.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>face_att_021181.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.003921569, 0.003921569, 0.003921569, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>face_att_021186.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.003921569, 0.003921569, 0.003921569, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>face_att_021209.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.6117647, 0.6117647, 0.6117647, 0.6117647, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>face_att_021216.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.69411767, 0.69411767, 0.69411767, 0.694117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>face_att_021221.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>face_att_021227.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.101960786, 0.09803922, 0.09803922, 0.09411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>face_att_021228.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.050980393, 0.050980393, 0.050980393, 0.050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>face_att_021231.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.85490197, 0.85490197, 0.85490197, 0.854901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>face_att_021232.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>face_att_021235.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.08235294, 0.078431375, 0.078431375, 0.0745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>face_att_021238.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.09803922, 0.09803922, 0.09411765, 0.090196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>face_att_021256.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.15294118, 0.15686275, 0.15686275, 0.160784...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>face_att_021258.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.32941177, 0.32941177, 0.32941177, 0.329411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>face_att_021261.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.18431373, 0.18039216, 0.18039216, 0.176470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>face_att_021265.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.7411765, 0.74509805, 0.70980394, 0.6470588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>face_att_021271.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.18431373, 0.2, 0.21568628, 0.23137255, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>face_att_021278.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.9490196, 0.9490196, 0.9490196, 0.9490196, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>face_att_021288.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.039215688, 0.043137256, 0.043137256, 0.043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>face_att_021291.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.7254902, 0.7254902, 0.7254902, 0.72156864,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>face_att_021293.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.90588236, 0.90588236, 0.90588236, 0.905882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>face_att_021306.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.15294118, 0.13333334, 0.105882354, 0.08235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>face_att_021311.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.105882354, 0.105882354, 0.105882354, 0.105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>face_att_021316.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.015686275, 0.015686275, 0.015686275, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>face_att_021318.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.49019608, 0.4862745, 0.48235294, 0.4745098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>face_att_021343.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.08627451, 0.101960786, 0.11372549, 0.11764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>face_att_021348.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.30980393, 0.3137255, 0.3137255, 0.3137255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>face_att_021358.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.3764706, 0.37254903, 0.37254903, 0.3725490...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    files label  \\\n",
       "0     face_att_000001.jpg   1.0   \n",
       "1     face_att_000004.jpg   1.0   \n",
       "2     face_att_000006.jpg   1.0   \n",
       "3     face_att_000009.jpg   1.0   \n",
       "4     face_att_000018.jpg   1.0   \n",
       "5     face_att_000024.jpg   1.0   \n",
       "6     face_att_000029.jpg   1.0   \n",
       "7     face_att_000039.jpg   1.0   \n",
       "8     face_att_000040.jpg   1.0   \n",
       "9     face_att_000042.jpg   1.0   \n",
       "10    face_att_000043.jpg   1.0   \n",
       "11    face_att_000045.jpg   1.0   \n",
       "12    face_att_000047.jpg   1.0   \n",
       "13    face_att_000057.jpg   1.0   \n",
       "14    face_att_000066.jpg   1.0   \n",
       "15    face_att_000071.jpg   1.0   \n",
       "16    face_att_000074.jpg   1.0   \n",
       "17    face_att_000083.jpg   1.0   \n",
       "18    face_att_000084.jpg   1.0   \n",
       "19    face_att_000085.jpg   1.0   \n",
       "20    face_att_000095.jpg   1.0   \n",
       "21    face_att_000106.jpg   1.0   \n",
       "22    face_att_000108.jpg   1.0   \n",
       "23    face_att_000111.jpg   1.0   \n",
       "24    face_att_000117.jpg   1.0   \n",
       "25    face_att_000122.jpg   1.0   \n",
       "26    face_att_000124.jpg   1.0   \n",
       "27    face_att_000132.jpg   1.0   \n",
       "28    face_att_000133.jpg   1.0   \n",
       "29    face_att_000148.jpg   1.0   \n",
       "...                   ...   ...   \n",
       "3970  face_att_021171.jpg   1.0   \n",
       "3971  face_att_021175.jpg   1.0   \n",
       "3972  face_att_021179.jpg   1.0   \n",
       "3973  face_att_021181.jpg   1.0   \n",
       "3974  face_att_021186.jpg   1.0   \n",
       "3975  face_att_021209.jpg   1.0   \n",
       "3976  face_att_021216.jpg   1.0   \n",
       "3977  face_att_021221.jpg   1.0   \n",
       "3978  face_att_021227.jpg   1.0   \n",
       "3979  face_att_021228.jpg   1.0   \n",
       "3980  face_att_021231.jpg   1.0   \n",
       "3981  face_att_021232.jpg   1.0   \n",
       "3982  face_att_021235.jpg   1.0   \n",
       "3983  face_att_021238.jpg   1.0   \n",
       "3984  face_att_021256.jpg   1.0   \n",
       "3985  face_att_021258.jpg   1.0   \n",
       "3986  face_att_021261.jpg   1.0   \n",
       "3987  face_att_021265.jpg   1.0   \n",
       "3988  face_att_021271.jpg   1.0   \n",
       "3989  face_att_021278.jpg   1.0   \n",
       "3990  face_att_021288.jpg   1.0   \n",
       "3991  face_att_021291.jpg   1.0   \n",
       "3992  face_att_021293.jpg   1.0   \n",
       "3993  face_att_021306.jpg   1.0   \n",
       "3994  face_att_021311.jpg   1.0   \n",
       "3995  face_att_021316.jpg   1.0   \n",
       "3996  face_att_021318.jpg   1.0   \n",
       "3997  face_att_021343.jpg   1.0   \n",
       "3998  face_att_021348.jpg   1.0   \n",
       "3999  face_att_021358.jpg   1.0   \n",
       "\n",
       "                                                  image  \n",
       "0     [[0.9137255, 0.9137255, 0.9137255, 0.9137255, ...  \n",
       "1     [[0.1882353, 0.3529412, 0.3764706, 0.34509805,...  \n",
       "2     [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "3     [[0.3019608, 0.29803923, 0.29803923, 0.2980392...  \n",
       "4     [[0.83137256, 0.83137256, 0.83137256, 0.831372...  \n",
       "5     [[0.47058824, 0.47058824, 0.47058824, 0.470588...  \n",
       "6     [[0.4, 0.38431373, 0.38039216, 0.38039216, 0.3...  \n",
       "7     [[0.74509805, 0.75686276, 0.77254903, 0.796078...  \n",
       "8     [[0.12941177, 0.12941177, 0.12941177, 0.133333...  \n",
       "9     [[0.20392157, 0.20784314, 0.20784314, 0.196078...  \n",
       "10    [[0.6901961, 0.6901961, 0.6901961, 0.6901961, ...  \n",
       "11    [[0.76862746, 0.7921569, 0.8, 0.8039216, 0.807...  \n",
       "12    [[0.8117647, 0.79607844, 0.7921569, 0.79607844...  \n",
       "13    [[0.83137256, 0.827451, 0.827451, 0.8235294, 0...  \n",
       "14    [[0.4509804, 0.45490196, 0.45490196, 0.4549019...  \n",
       "15    [[0.4745098, 0.47058824, 0.46666667, 0.4627451...  \n",
       "16    [[0.93333334, 0.93333334, 0.93333334, 0.933333...  \n",
       "17    [[0.6509804, 0.654902, 0.65882355, 0.6627451, ...  \n",
       "18    [[0.23137255, 0.22352941, 0.21176471, 0.203921...  \n",
       "19    [[0.54509807, 0.54509807, 0.54509807, 0.545098...  \n",
       "20    [[0.16470589, 0.16470589, 0.16470589, 0.164705...  \n",
       "21    [[0.003921569, 0.003921569, 0.003921569, 0.003...  \n",
       "22    [[0.28627452, 0.29803923, 0.29803923, 0.290196...  \n",
       "23    [[0.99607843, 0.99607843, 0.99607843, 0.996078...  \n",
       "24    [[0.8235294, 0.827451, 0.8666667, 0.9098039, 0...  \n",
       "25    [[0.23529412, 0.23137255, 0.23137255, 0.231372...  \n",
       "26    [[0.76862746, 0.77254903, 0.77254903, 0.776470...  \n",
       "27    [[0.9607843, 0.9607843, 0.9607843, 0.9607843, ...  \n",
       "28    [[0.22352941, 0.21568628, 0.20784314, 0.223529...  \n",
       "29    [[0.1254902, 0.1254902, 0.1254902, 0.1254902, ...  \n",
       "...                                                 ...  \n",
       "3970  [[0.99607843, 0.99607843, 0.99607843, 0.996078...  \n",
       "3971  [[0.003921569, 0.003921569, 0.003921569, 0.003...  \n",
       "3972  [[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,...  \n",
       "3973  [[0.003921569, 0.003921569, 0.003921569, 0.003...  \n",
       "3974  [[0.003921569, 0.003921569, 0.003921569, 0.003...  \n",
       "3975  [[0.6117647, 0.6117647, 0.6117647, 0.6117647, ...  \n",
       "3976  [[0.69411767, 0.69411767, 0.69411767, 0.694117...  \n",
       "3977  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3978  [[0.101960786, 0.09803922, 0.09803922, 0.09411...  \n",
       "3979  [[0.050980393, 0.050980393, 0.050980393, 0.050...  \n",
       "3980  [[0.85490197, 0.85490197, 0.85490197, 0.854901...  \n",
       "3981  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3982  [[0.08235294, 0.078431375, 0.078431375, 0.0745...  \n",
       "3983  [[0.09803922, 0.09803922, 0.09411765, 0.090196...  \n",
       "3984  [[0.15294118, 0.15686275, 0.15686275, 0.160784...  \n",
       "3985  [[0.32941177, 0.32941177, 0.32941177, 0.329411...  \n",
       "3986  [[0.18431373, 0.18039216, 0.18039216, 0.176470...  \n",
       "3987  [[0.7411765, 0.74509805, 0.70980394, 0.6470588...  \n",
       "3988  [[0.18431373, 0.2, 0.21568628, 0.23137255, 0.2...  \n",
       "3989  [[0.9490196, 0.9490196, 0.9490196, 0.9490196, ...  \n",
       "3990  [[0.039215688, 0.043137256, 0.043137256, 0.043...  \n",
       "3991  [[0.7254902, 0.7254902, 0.7254902, 0.72156864,...  \n",
       "3992  [[0.90588236, 0.90588236, 0.90588236, 0.905882...  \n",
       "3993  [[0.15294118, 0.13333334, 0.105882354, 0.08235...  \n",
       "3994  [[0.105882354, 0.105882354, 0.105882354, 0.105...  \n",
       "3995  [[0.015686275, 0.015686275, 0.015686275, 0.015...  \n",
       "3996  [[0.49019608, 0.4862745, 0.48235294, 0.4745098...  \n",
       "3997  [[0.08627451, 0.101960786, 0.11372549, 0.11764...  \n",
       "3998  [[0.30980393, 0.3137255, 0.3137255, 0.3137255,...  \n",
       "3999  [[0.3764706, 0.37254903, 0.37254903, 0.3725490...  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [test['files'][test['label']=='1.0'], test['files'][test['label']=='0.0']]\n",
    "titles = ['Eyeglasses', 'W/O Eyeglasses']\n",
    "\n",
    "for l, j, t in zip(labels, range(1,3), titles):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for i in range(5):\n",
    "        file = l.sample().values[0]\n",
    "        file_path = find_imagepath(file)\n",
    "        img = mpimg.imread(file_path)\n",
    "        ax = plt.subplot(2, 5, i+1)\n",
    "        plt.suptitle(t)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhWSv75qOYW5"
   },
   "source": [
    "#### `ImageDataGenerator` class \n",
    "load our dataset as an iterator (not keeping it all in memory at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3e7h8C_UkXD"
   },
   "outputs": [],
   "source": [
    "train['label'] = train['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 38556,
     "status": "ok",
     "timestamp": 1599833202206,
     "user": {
      "displayName": "Tal T",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi2JEqenXMt8KQ0yJDTMq6jL2fP9wTV8ULQdEoZaw=s64",
      "userId": "04492565207152809606"
     },
     "user_tz": -180
    },
    "id": "o2PXUMLbXg9H",
    "outputId": "e7bb74d4-2e9d-404a-85a4-971f37c8170c"
   },
   "outputs": [],
   "source": [
    "train_data = img_gen.flow_from_dataframe(train,\n",
    "                                         directory=FACEPATH+'/1/',\n",
    "                                         x_col='files', \n",
    "                                         y_col='label', \n",
    "                                         class_mode='binary', \n",
    "                                         batch_size=64, \n",
    "                                         target_size=(224, 224), \n",
    "                                         subset='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 38556,
     "status": "ok",
     "timestamp": 1599833202206,
     "user": {
      "displayName": "Tal T",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi2JEqenXMt8KQ0yJDTMq6jL2fP9wTV8ULQdEoZaw=s64",
      "userId": "04492565207152809606"
     },
     "user_tz": -180
    },
    "id": "o2PXUMLbXg9H",
    "outputId": "e7bb74d4-2e9d-404a-85a4-971f37c8170c"
   },
   "outputs": [],
   "source": [
    "valid_data = img_gen.flow_from_dataframe(train,\n",
    "                                         directory=FACEPATH+'/1/',\n",
    "                                         x_col='files', \n",
    "                                         y_col='label', \n",
    "                                         class_mode='binary', \n",
    "                                         batch_size=64, \n",
    "                                         target_size=(224, 224), \n",
    "                                         subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen_test = ImageDataGenerator()\n",
    "test_data = img_gen_test.flow_from_dataframe(test,\n",
    "                                        directory=FACEPATH+'/1/',\n",
    "                                        x_col='files', \n",
    "                                        y_col='label',\n",
    "                                        class_mode=None, \n",
    "                                        target_size=(224,224), \n",
    "                                        batch_size=64, \n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FaceDetection Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model):\n",
    "    \"\"\"\n",
    "    load face detection models\n",
    "    \"\"\"\n",
    "    models = {'vgg_face': VGGFace,\n",
    "              'open_face': OpenFace,\n",
    "              'facenet': Facenet,\n",
    "              'deep_face': FbDeepFace,\n",
    "              'deep_id': DeepID,\n",
    "              \n",
    "              \"emotion\": Emotion,\n",
    "              \"age\": Age,\n",
    "              \"gender\": Gender,\n",
    "              \"race\": Race}\n",
    "    \n",
    "    return models[model].loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 47200,
     "status": "ok",
     "timestamp": 1599833210873,
     "user": {
      "displayName": "Tal T",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi2JEqenXMt8KQ0yJDTMq6jL2fP9wTV8ULQdEoZaw=s64",
      "userId": "04492565207152809606"
     },
     "user_tz": -180
    },
    "id": "ej0sUvnZzdag",
    "outputId": "2939095f-9f76-45f4-8b1a-9a314b70026a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_summary(model):\n",
    "    print(f\"Input_shape:\\t{model.input_shape}\\nOutput_shape:\\t{model.output_shape}\\nParams:\\t{model.count_params()} \\\n",
    "    \\nLayers:\\t{len(model.layers)}\\n\\n\")\n",
    "    return model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 47200,
     "status": "ok",
     "timestamp": 1599833210873,
     "user": {
      "displayName": "Tal T",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi2JEqenXMt8KQ0yJDTMq6jL2fP9wTV8ULQdEoZaw=s64",
      "userId": "04492565207152809606"
     },
     "user_tz": -180
    },
    "id": "ej0sUvnZzdag",
    "outputId": "2939095f-9f76-45f4-8b1a-9a314b70026a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# By default, it loads weights pre-trained on ImageNet. \n",
    "vgg16 = tf.keras.applications.vgg16.VGG16(include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 47200,
     "status": "ok",
     "timestamp": 1599833210873,
     "user": {
      "displayName": "Tal T",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi2JEqenXMt8KQ0yJDTMq6jL2fP9wTV8ULQdEoZaw=s64",
      "userId": "04492565207152809606"
     },
     "user_tz": -180
    },
    "id": "ej0sUvnZzdag",
    "outputId": "2939095f-9f76-45f4-8b1a-9a314b70026a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_summary(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                         Top Layers Removed:\n",
    "# flatten (Flatten)            (None, 25088)             0         \n",
    "# _________________________________________________________________\n",
    "# fc1 (Dense)                  (None, 4096)              102764544 \n",
    "# _________________________________________________________________\n",
    "# fc2 (Dense)                  (None, 4096)              16781312  \n",
    "# _________________________________________________________________\n",
    "# predictions (Dense)          (None, 1000)              4097000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "facenet = load_model('facenet')\n",
    "print_summary(facenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VggFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vggface = load_model('vgg_face')\n",
    "print_summary(vggface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYSE1ux4OYW8"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx6hmWN3OYW-"
   },
   "source": [
    "Adding new model `model` whose first layer is `vggface/vgg_face` with additional layers \n",
    "(from `tensorflow.keras.layers`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_toplayers(base_model):\n",
    "    \"\"\"\n",
    "    Function takes basemodel and add top layers\n",
    "    \"\"\"\n",
    "    base_model.trainable=False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    print_summary(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = 2\n",
    "# base_model_output = Sequential()\n",
    "# base_model_output = Convolution2D(classes, (1, 1), name='predictions')(basemodel.layers[-4].output)\n",
    "# base_model_output = Flatten()(base_model_output)\n",
    "# base_model_output = Dense(128, activation='relu')(base_model_output)\n",
    "# base_model_output = Dense(2, activation='relu')(base_model_output)\n",
    "# base_model_output = Activation('relu')(base_model_output)\n",
    "# model = Model(inputs=vggface.input, outputs=base_model_output)\n",
    "# -----------------------------------------------------------\n",
    "# model = Sequential()\n",
    "# model.add(basemodel)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# ------------------------------------------------------------\n",
    "# model = Sequential()\n",
    "# model = Convolution2D(classes, (1, 1), name='predictions')(basemodel.layers[-4].output)\n",
    "# model = Flatten()(model)\n",
    "# model = Activation('relu')(model)\n",
    "# model = Flatten()(model)\n",
    "# model = Convolution2D(64, 3, padding='same', input_shape=(32,32,3))(model)\n",
    "# model = Activation('relu')(model)\n",
    "# model = Convolution2D(64, (3, 3))(model)\n",
    "# model = Activation('relu')(model)\n",
    "# model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "# model = Dropout(0.25)(model)\n",
    "# model = Convolution2D(32, (3, 3), padding='same')(model)\n",
    "# model = Activation('relu')(model)\n",
    "# model = Convolution2D(32, (3, 3))(model)\n",
    "# model = Activation('relu')(model)\n",
    "# model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "# model = Dropout(0.25)(model)\n",
    "# model = Flatten()(model)\n",
    "# model = Dense(512)(model)\n",
    "# model = Activation('relu')(model)\n",
    "# model = Dropout(0.5)(model)\n",
    "# model = Dense(10, activation='relu')(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djCoifqrOYW_"
   },
   "source": [
    "To train our transfer learning model we will freeze the weights of the basemodel and only train the added layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_vgg16 = adding_toplayers(vgg16)\n",
    "mod_facenet = adding_toplayers(facenet)\n",
    "mod_vggface = adding_toplayers(vggface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mod_vgg16, mod_vggface, mod_facenet]\n",
    "model = mod_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callback_list = [earlystopper, checkpoint]\n",
    "\n",
    "# Optimzing\n",
    "model.compile(optimizers.RMSprop(lr=0.0001, decay=1e-6),loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# Fitting\n",
    "STEP_SIZE_TRAIN=train_data.n//train_data.batch_size\n",
    "STEP_SIZE_VALID=valid_data.n//valid_data.batch_size\n",
    "STEP_SIZE_TEST=test_data.n//test_data.batch_size\n",
    "EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data,\n",
    "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "          validation_data=valid_data,\n",
    "          validation_steps=STEP_SIZE_VALID,\n",
    "          callbacks=callback_list,\n",
    "          epochs=EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(valid_data,steps=STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loss:\\t{round(loss,2)}\\nAcc.:\\t{round(acc,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(18,5))\n",
    "# ax.plot(np.arange(1, EPOCH), history.history[\"loss\"], label=\"train\")\n",
    "# plt.plot(np.arange(1, EPOCH), history.history[\"val_loss\"], label=\"val\")\n",
    "# plt.plot(np.arange(1, EPOCH), history.history[\"accuracy\"], label=\"train\")\n",
    "# plt.plot(np.arange(1, EPOCH), history.history[\"val_accuracy\"], label=\"val\")\n",
    "# plt.suptitle(\"Val & Train Loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Acc\")\n",
    "# plt.legend(loc=\"middle right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(cm, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames_test = test_data.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6-V2ggbnWlj"
   },
   "outputs": [],
   "source": [
    "test_data.reset()\n",
    "pred = model.predict(test_data,\n",
    "                     steps=STEP_SIZE_TEST,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = list(map(lambda x: 1 if float(x) >= 0.2 else 0 , pred))# {1.0:'With',0.0:'W/O'}\n",
    "pd.DataFrame(data=(filenames_test, y_pred, test['files'], test['label'])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices = np.argmax(pred, axis=1)\n",
    "labels = (train_data.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_data.filenames\n",
    "s = len(predictions)\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results['Predictions'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(img_path, actions = [], models = {}, enforce_detection = True, detector_backend = 'opencv'):\n",
    "\n",
    "    if type(img_path) == list:\n",
    "        img_paths = img_path.copy()\n",
    "        bulkProcess = True\n",
    "    else:\n",
    "        img_paths = [img_path]\n",
    "        bulkProcess = False\n",
    "\n",
    "    #---------------------------------\n",
    "\n",
    "    #if a specific target is not passed, then find them all\n",
    "    if len(actions) == 0:\n",
    "        actions= ['emotion', 'age', 'gender', 'race', 'eyeglass']\n",
    "\n",
    "    #print(\"Actions to do: \", actions)\n",
    "\n",
    "    #---------------------------------\n",
    "\n",
    "    if 'emotion' in actions:\n",
    "        if 'emotion' in models:\n",
    "            print(\"already built emotion model is passed\")\n",
    "            emotion_model = models['emotion']\n",
    "        else:\n",
    "            emotion_model = Emotion.loadModel()\n",
    "\n",
    "    if 'age' in actions:\n",
    "        if 'age' in models:\n",
    "            print(\"already built age model is passed\")\n",
    "            age_model = models['age']\n",
    "        else:\n",
    "            age_model = Age.loadModel()\n",
    "\n",
    "    if 'gender' in actions:\n",
    "        if 'gender' in models:\n",
    "            print(\"already built gender model is passed\")\n",
    "            gender_model = models['gender']\n",
    "        else:\n",
    "            gender_model = Gender.loadModel()\n",
    "\n",
    "    if 'race' in actions:\n",
    "        if 'race' in models:\n",
    "            print(\"already built race model is passed\")\n",
    "            race_model = models['race']\n",
    "        else:\n",
    "            race_model = Race.loadModel()\n",
    "            \n",
    "    if 'eyeglass' in actions:\n",
    "        if 'eyeglass' in models:\n",
    "            print(\"already built race model is passed\")\n",
    "            eyeglass_model = models['eyeglass']\n",
    "        else:\n",
    "            eyeglass_model = model.load_weightsweights('eyeglass.h5')\n",
    "    #---------------------------------\n",
    "\n",
    "    resp_objects = []\n",
    "\n",
    "    disable_option = False if len(img_paths) > 1 else True\n",
    "\n",
    "    global_pbar = tqdm(range(0,len(img_paths)), desc='Analyzing', disable = disable_option)\n",
    "\n",
    "    #for img_path in img_paths:\n",
    "    for j in global_pbar:\n",
    "        img_path = img_paths[j]\n",
    "\n",
    "        resp_obj = \"{\"\n",
    "\n",
    "        disable_option = False if len(actions) > 1 else True\n",
    "\n",
    "        pbar = tqdm(range(0,len(actions)), desc='Finding actions', disable = disable_option)\n",
    "\n",
    "        action_idx = 0\n",
    "        img_224 = None # Set to prevent re-detection\n",
    "        #for action in actions:\n",
    "        for index in pbar:\n",
    "            action = actions[index]\n",
    "            pbar.set_description(\"Action: %s\" % (action))\n",
    "\n",
    "            if action_idx > 0:\n",
    "                resp_obj += \", \"\n",
    "\n",
    "            if action == 'emotion':\n",
    "                emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "                img = functions.preprocess_face(img = img_path, target_size = (48, 48), grayscale = True, enforce_detection = enforce_detection, detector_backend = detector_backend)\n",
    "\n",
    "                emotion_predictions = emotion_model.predict(img)[0,:]\n",
    "\n",
    "                sum_of_predictions = emotion_predictions.sum()\n",
    "\n",
    "                emotion_obj = \"\\\"emotion\\\": {\"\n",
    "                for i in range(0, len(emotion_labels)):\n",
    "                    emotion_label = emotion_labels[i]\n",
    "                    emotion_prediction = 100 * emotion_predictions[i] / sum_of_predictions\n",
    "\n",
    "                    if i > 0: emotion_obj += \", \"\n",
    "\n",
    "                    emotion_obj += \"\\\"%s\\\": %s\" % (emotion_label, emotion_prediction)\n",
    "\n",
    "                emotion_obj += \"}\"\n",
    "\n",
    "                emotion_obj += \", \\\"dominant_emotion\\\": \\\"%s\\\"\" % (emotion_labels[np.argmax(emotion_predictions)])\n",
    "\n",
    "                resp_obj += emotion_obj\n",
    "\n",
    "            elif action == 'age':\n",
    "                if img_224 is None:\n",
    "                    img_224 = functions.preprocess_face(img_path, target_size = (224, 224), grayscale = False, enforce_detection = enforce_detection) #just emotion model expects grayscale images\n",
    "                #print(\"age prediction\")\n",
    "                age_predictions = age_model.predict(img_224)[0,:]\n",
    "                apparent_age = Age.findApparentAge(age_predictions)\n",
    "\n",
    "                resp_obj += \"\\\"age\\\": %s\" % (apparent_age)\n",
    "\n",
    "            elif action == 'gender':\n",
    "                if img_224 is None:\n",
    "                    img_224 = functions.preprocess_face(img = img_path, target_size = (224, 224), grayscale = False, enforce_detection = enforce_detection, detector_backend = detector_backend) #just emotion model expects grayscale images\n",
    "                #print(\"gender prediction\")\n",
    "\n",
    "                gender_prediction = gender_model.predict(img_224)[0,:]\n",
    "\n",
    "                if np.argmax(gender_prediction) == 0:\n",
    "                    gender = \"Woman\"\n",
    "                elif np.argmax(gender_prediction) == 1:\n",
    "                    gender = \"Man\"\n",
    "            \n",
    "            elif action == 'eyeglass':\n",
    "                if img_224 is None:\n",
    "                    img_224 = functions.preprocess_face(img = img_path, target_size = (224, 224), grayscale = False, enforce_detection = enforce_detection, detector_backend = detector_backend) #just emotion model expects grayscale images\n",
    "                #print(\"gender prediction\")\n",
    "\n",
    "                eyeglass_prediction = eyeglass_model.predict(img_224)[0,:]\n",
    "\n",
    "                if np.argmax(eyeglass_prediction) == 0:\n",
    "                    eg = \"W/O Eyeglasses\"\n",
    "                elif np.argmax(eyeglass_prediction) == 1:\n",
    "                    eg = \"With Eyeglasses\"\n",
    "\n",
    "\n",
    "                resp_obj += \"\\\"eyeglass\\\": \\\"%s\\\"\" % (eg)\n",
    "\n",
    "            elif action == 'race':\n",
    "                if img_224 is None:\n",
    "                    img_224 = functions.preprocess_face(img = img_path, target_size = (224, 224), grayscale = False, enforce_detection = enforce_detection, detector_backend = detector_backend) #just emotion model expects grayscale images\n",
    "                race_predictions = race_model.predict(img_224)[0,:]\n",
    "                race_labels = ['asian', 'indian', 'black', 'white', 'middle eastern', 'latino hispanic']\n",
    "\n",
    "                sum_of_predictions = race_predictions.sum()\n",
    "\n",
    "                race_obj = \"\\\"race\\\": {\"\n",
    "                for i in range(0, len(race_labels)):\n",
    "                    race_label = race_labels[i]\n",
    "                    race_prediction = 100 * race_predictions[i] / sum_of_predictions\n",
    "\n",
    "                    if i > 0: race_obj += \", \"\n",
    "\n",
    "                    race_obj += \"\\\"%s\\\": %s\" % (race_label, race_prediction)\n",
    "\n",
    "                race_obj += \"}\"\n",
    "                race_obj += \", \\\"dominant_race\\\": \\\"%s\\\"\" % (race_labels[np.argmax(race_predictions)])\n",
    "\n",
    "                resp_obj += race_obj\n",
    "\n",
    "            action_idx = action_idx + 1\n",
    "\n",
    "        resp_obj += \"}\"\n",
    "\n",
    "        resp_obj = json.loads(resp_obj)\n",
    "\n",
    "        if bulkProcess == True:\n",
    "            resp_objects.append(resp_obj)\n",
    "        else:\n",
    "            return resp_obj\n",
    "\n",
    "    if bulkProcess == True:\n",
    "        resp_obj = \"{\"\n",
    "\n",
    "        for i in range(0, len(resp_objects)):\n",
    "            resp_item = json.dumps(resp_objects[i])\n",
    "\n",
    "            if i > 0:\n",
    "                resp_obj += \", \"\n",
    "\n",
    "            resp_obj += \"\\\"instance_\"+str(i+1)+\"\\\": \"+resp_item\n",
    "        resp_obj += \"}\"\n",
    "        resp_obj = json.loads(resp_obj)\n",
    "        return resp_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_face(df, backend=0):\n",
    "    \"\"\"\n",
    "    Function call image file as str or from dataframe and analyze it with deepface module to extract\n",
    "    race, age, gender and emotion\n",
    "    \"\"\"\n",
    "    \n",
    "    # reading file\n",
    "    if isinstance(df, str):\n",
    "        file = find_imagepath(df)\n",
    "    else:\n",
    "        img_f1 = df.sample().values[0]\n",
    "        file = find_imagepath(img_f1)\n",
    "    \n",
    "    # Run DeepFace\n",
    "    try:\n",
    "        backends = ['opencv', 'ssd', 'dlib', 'mtcnn']\n",
    "        demography = DeepFace.analyze(file, detector_backend = backends[backend])\n",
    "        age = int(demography['age'])\n",
    "        gender = demography['gender']\n",
    "        emotion = demography['dominant_emotion']\n",
    "        race = demography['dominant_race']\n",
    "        textstr = f'Age:\\t\\t{age}\\nGender:\\t\\t{gender}\\nRace:\\t\\t{race.title()}\\nEmotion:\\t{emotion.title()}'\n",
    "\n",
    "    except ValueError: \n",
    "        print('Face could not be detected')\n",
    "        sys.exit()\n",
    "        \n",
    "    # Plot\n",
    "    plt.figure(figsize=(5,5))\n",
    "    img = mpimg.imread(file)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    print(textstr)\n",
    "# DeepFace.verify(\"img1.jpg\", \"img2.jpg\", model_name = \"VGG-Face\", model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeglass_model = tf.saved_model.load(os.path.join(os.getcwd(), 'eyeglass.h5'))\n",
    "model.load('eyeglass.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_shapes = ([90000], ())\n",
    "analyze_face(results['Filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepFace.stream(IMAGEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CV_Ex1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
