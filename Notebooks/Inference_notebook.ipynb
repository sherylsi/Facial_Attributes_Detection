{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "from Classes.LoadModel import BaseModel\n",
    "from Classes import Predict\n",
    "# import memory_profiler\n",
    "\n",
    "from Classes.Predict import analyze_face, Prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "from config import *\n",
    "import random\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Layer, Input, Dropout, Activation, Convolution2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 0\n",
    "LABEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_layers_vggface1(model_base):\n",
    "    model_base.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(model_base)\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_layers_vggface7(model_base):\n",
    "    model_base.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(model_base)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(model_name, label):\n",
    "    # Loading BaseModel\n",
    "    if model_name in ['emotion', 'gender', 'age', 'race']:\n",
    "        basemodel = BaseModel(model_name)\n",
    "    else:\n",
    "        basemodel = BaseModel(model_name[:-1])\n",
    "    model = basemodel.load_model(False)\n",
    "    if label.lower() not in ['race', 'gender', 'emotion', 'age', 'hair_color'] :\n",
    "        model = top_layers_vggface1(model)\n",
    "        print('vggface1 layers loaded')\n",
    "    elif 'hair' in label.lower():\n",
    "        model = top_layers_vggface7(model)\n",
    "        print('vggface7 layers loaded')\n",
    "    else:\n",
    "        model = model \n",
    "        print(att, 'model loaded')\n",
    "    # Loading Best Model\n",
    "    model.load_weights(os.path.join(MOD_ATT_PATH, f'{model_name}_{label}.h5'))\n",
    "    print(f\"\\nBest Model {model_name}'s Arc. and Weights Loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Inference...\n",
      "vggface1\n",
      "vggface1 layers loaded\n",
      "\n",
      "Best Model vggface1's Arc. and Weights Loaded!\n",
      "age_model_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1YCox_4kJ-BYeXq27uUbasu--yz28zUMV\n",
      "To: /home/ubuntu/.deepface/weights/age_model_weights.h5\n",
      "539MB [00:04, 121MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_model_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wUXRVlbsni2FN9-jkS_f4UTUrm1bRLyk\n",
      "To: /home/ubuntu/.deepface/weights/gender_model_weights.h5\n",
      "537MB [00:08, 59.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_model_single_batch.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1nz-WDhghGQBC4biwShQ9kYjvQMpO6smj\n",
      "To: /home/ubuntu/.deepface/weights/race_model_single_batch.zip\n",
      "511MB [00:05, 85.7MB/s] \n",
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.14it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face could not be detected\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-43f5ba9ce3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-43f5ba9ce3a4>\u001b[0m in \u001b[0;36minference\u001b[0;34m(image_path, best_pairs, plot)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# running rage models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresult_rage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_rage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# running binaryCls models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mbicls_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicls_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "# Taking Best Model per Att\n",
    "\n",
    "IMAGE_PATH = '/home/ubuntu/sheryl/face_att_sheryl'\n",
    "IND_FILE = '/home/ubuntu/jonathan/files_list.csv'\n",
    "WEIGHT_PATH = '/home/ubuntu/sheryl/Facial_Attributes_Detection/Weights'\n",
    "MOD_ATT_PATH =  '/home/ubuntu/sheryl/Facial_Attributes_Detection/model-att'\n",
    "\n",
    "models_list = [file for file in os.listdir(MOD_ATT_PATH) if str(file).endswith('h5')]\n",
    "best_model_list = []\n",
    "label_list = []\n",
    "best_pairs = []\n",
    "# modelz = '/Users/tal/Dropbox/Projects/vggface_Eyeglasses.h5'\n",
    "\n",
    "for model in models_list:\n",
    "    best_model = model.split('/')[-1].split('_')[MODEL]\n",
    "    label = ''.join(model.strip('.h5').split('_')[LABEL:])\n",
    "    best_model_list.append(best_model)\n",
    "    label_list.append(label)\n",
    "\n",
    "best_pairs = zip(best_model_list, label_list)\n",
    "\n",
    "print('Running Inference...')\n",
    "label_query = ['Eyeglasses']\n",
    "\n",
    "\n",
    "def inference(image_path, best_pairs, plot=False):\n",
    "\n",
    "    # Get img list\n",
    "    img_list = os.listdir(IMAGE_PATH)\n",
    "    file = ''.join(random.choices(img_list, k=1))\n",
    "    result = []\n",
    "    score = []\n",
    "    tic = time()\n",
    "    file = os.path.join(image_path, file)\n",
    "\n",
    "    for model_name, label in best_pairs:\n",
    "        print(model_name)\n",
    "        pos, neg = f'{label}: V', f'{label}: X'\n",
    "        model = load_best_model(model_name, label)\n",
    "\n",
    "        # running rage models\n",
    "        result_rage, score_rage = analyze_face(file)\n",
    "        # running binaryCls models\n",
    "        bicls_result, bicls_score = Predict.predict_file(model, file, pos, neg)\n",
    "        # running multiCls models ** I changed only here the label dict onmain it stays the same\n",
    "        # labels_hair = {0: 'Bald', 1: 'Black_Hair', 2: 'Blond_Hair', 3: 'Brown_Hair', 4: 'Gray_Hair'}\n",
    "        # result.append(Prediction.predict_label_multi(model, labels_hair, file, 'ResNet50'))\n",
    "\n",
    "        result.append(bicls_result+result_rage)\n",
    "        file_dict = {file: {label: score}}\n",
    "\n",
    "        # update dictionary\n",
    "        json_file = PATH_JSON + 'sum_file.json'\n",
    "        with open(json_file, 'r') as jf:\n",
    "            json_obj = json.load(jf)\n",
    "        json_obj[file] = file_dict\n",
    "        json_obj[file].update(score_rage)\n",
    "        json_obj[file][label] = bicls_score[0][0].astype(float)\n",
    "\n",
    "        with open(json_file, \"w\") as jf_out:\n",
    "            json.dump(json_obj, jf_out)\n",
    "\n",
    "    toc = time()\n",
    "    run = toc - tic\n",
    "    print(f'Avg Time inference {(run / 60)/len(models_list):.2f} minutes.')\n",
    "\n",
    "    if plot:\n",
    "        result = ''.join(result)\n",
    "        img = mpimg.imread(file)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.imshow(img)\n",
    "        plt.text(s=result, x=190, y=100)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "    return file_dict\n",
    "\n",
    "\n",
    "result = inference(IMAGE_PATH, best_pairs)\n",
    "print(result)\n",
    "\n",
    "# sum_json =\n",
    "# print(sum_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
