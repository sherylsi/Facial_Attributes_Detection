{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Classes.LoadModel import BaseModel\n",
    "from Classes.Predict import Prediction\n",
    "from config import *\n",
    "from Classes.Train import *\n",
    "from Classes.Summarize import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading File...\n",
      "Creating Train, Test...\n",
      "Eyeglasses\n",
      "Starting Image Preprocessing\n",
      "Done!\n",
      "Creating Negative Class\n",
      "Negative class files:\t198052\n",
      "Taking 10 Images\n",
      "Starting data splitting\n",
      "Done!\n",
      "Train shape: \t(8, 2)\n",
      "Test shape: \t(2, 2)\n",
      "Assertions Passed! Sets  Are of image files W/O Duplication\n",
      "Shape with Negative class:\n",
      "Train shape: \t(16, 3)\n",
      "Test shape: \t(4, 3)\n",
      "Assertions Passed! Sets  Are of image files W/O Duplication\n",
      "Done!\n",
      "\n",
      "Running data generator...\n",
      "Found 13 validated image filenames belonging to 2 classes.\n",
      "Found 3 validated image filenames belonging to 2 classes.\n",
      "Found 4 validated image filenames.\n",
      "\n",
      "Loading Model...\n",
      "Pick a Model: vgg19, MobileNetV2, vgg_face, facenet, emotion, age, gender, race\n",
      "\n",
      "Training Start...\n",
      "Input_shape:\t(None, 224, 224, 3)\n",
      "Output_shape:\t(None, 7, 7, 512)\n",
      "Params:\t20024384\n",
      "Layer:\t22\n",
      "\n",
      "\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input_shape:\t(None, 224, 224, 3)\n",
      "Output_shape:\t(None, 1)\n",
      "Params:\t23235905\n",
      "Layer:\t4\n",
      "\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 23,235,905\n",
      "Trainable params: 3,211,521\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'logs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9572d991c9ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-9572d991c9ab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasemodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasemodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madding_toplayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             history, model = trainer.start_train(model, model_file, train_data, valid_data, epoch, callback=None,\n\u001b[0m\u001b[1;32m     56\u001b[0m                                                  optimize=None)\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading best weights...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Facial_Attributes_Detection_Git/Classes/Train.py\u001b[0m in \u001b[0;36mstart_train\u001b[0;34m(self, model, savefile, train_set, valid_set, epoch, callback, optimize, multi)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mSTEP_SIZE_TRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mSTEP_SIZE_VALID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         history = model.fit(train_set,\n\u001b[0m\u001b[1;32m    228\u001b[0m                             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;31m# Run validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'logs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Classes.LoadModel import BaseModel\n",
    "from Classes.Predict import Prediction\n",
    "from config import *\n",
    "from Classes.Train import *\n",
    "from Classes.Summarize import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from BaseCls import run_ensemble\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def main():\n",
    "    imagepath = '/Users/Sheryl/Desktop/ITC2/Cellebrite Project/face_att_sheryl'  # os.path.join(FACEPATH, '1')\n",
    "    indexfile_path = '/Users/Sheryl/Desktop/ITC2/Cellebrite Project/files_list_sheryl.csv'\n",
    "\n",
    "\n",
    "    # Start images processing and dataframe splitting\n",
    "    trainer = Train(indexfile_path, imagepath)\n",
    "    print('Reading File...\\nCreating Train, Test...')\n",
    "    label = 'Eyeglasses' # , 'Wearing_Hat', 'Wearing_Earrings']\n",
    "    print(label)\n",
    "    train, test = trainer.data_preprocess(indexfile_path, label, 10, True, 224)\n",
    "    print('Done!')\n",
    "\n",
    "    # print(train['image'].shape)\n",
    "    # run_ensemble(train['image'], train['label'], test['image'], test['label'])\n",
    "\n",
    "\n",
    "    # print('Checking test sample images...')\n",
    "    # trainer.sanity_check(test)\n",
    "\n",
    "    # Split Train, Validation and Test Sets\n",
    "    print(f'\\nRunning data generator...')\n",
    "    train_data, valid_data, test_data = trainer.generator_splitter(train, test, imagepath)\n",
    "\n",
    "    # Loading Base Model\n",
    "    print(f'\\nLoading Model...')\n",
    "    model_list = ['vgg19', 'MobileNetV2', 'vgg_face', 'facenet']  #, 'emotion', 'age', 'gender', 'race']\n",
    "    print('Pick a Model: vgg19, MobileNetV2, vgg_face, facenet, emotion, age, gender, race')\n",
    "    for model_name in model_list:\n",
    "        # model_name  = 'vgg_face'  # input('Choose one model to load: )\n",
    "\n",
    "        # Training\n",
    "        print(f'\\nTraining Start...')\n",
    "        basemodel = BaseModel(model_name)\n",
    "\n",
    "        model_file = model_name + '_' + label + '.h5'\n",
    "        epoch = 100\n",
    "        training = True\n",
    "\n",
    "        if training:\n",
    "            model = basemodel.load_model()\n",
    "            model = basemodel.adding_toplayer(model)\n",
    "            history, model = trainer.start_train(model, model_file, train_data, valid_data, epoch, callback=None,\n",
    "                                                 optimize=None)\n",
    "            print('Loading best weights...')\n",
    "            model.load_weights(model_file)\n",
    "            print('Done!')\n",
    "\n",
    "            # Saving History\n",
    "            with open(model_name + '_' + label + '.json', 'w') as f:\n",
    "                json.dump(history.history, f)\n",
    "        else:\n",
    "            history = json.load(open(model_name + '_' + label + '.json'))\n",
    "            model = basemodel.load_model(False)\n",
    "            model = basemodel.adding_toplayer(model)\n",
    "            print(f'\\nModel {model_name} Loaded!')\n",
    "\n",
    "            print('Loading best weights...')\n",
    "            model.load_weights(os.path.join(MODEL_PATH, model_file))\n",
    "\n",
    "            opt_list = {'lr': [0.001, 0.005, 0.0001, 0.0005], 'decay': [1e-6]}\n",
    "            model.compile(RMSprop(lr=0.0001, decay=1e-6), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "        # Evaluate the network on valid data\n",
    "        # Prediction.evaluate_model(model, valid_data)\n",
    "\n",
    "        # Predict on test data\n",
    "        y_pred = Prediction.test_prediction(model, test_data, train_data)\n",
    "\n",
    "        # plot\n",
    "        top = min(len(test['label']), len(y_pred))\n",
    "        metrics = Metrics(history, epoch, test['label'][:top].tolist(), y_pred[:top], model_name, label)\n",
    "        metrics.confusion_matrix()\n",
    "        metrics.acc_loss_graph()\n",
    "        metrics.classification_report()\n",
    "\n",
    "\n",
    "    \"\"\"   # Inference\n",
    "    labels = [test['files'][test['label'] == '1.0'], test['files'][test['label'] == '0.0']]\n",
    "    pos, neg = f'With {label}', f'W/O {label}'\n",
    "    Prediction.predict_label(model, labels, pos, neg)\n",
    "    file = '/Users/tal/Google Drive/Cellebrite/Datasets/face_att/3/face_att_174563.jpg'\n",
    "    Prediction.predict_file(model, file, pos, neg)\n",
    "\n",
    "    model.load_weights(os.path.join(MODEL_PATH, model_file))\n",
    "\n",
    "    # layer_name = 'my_dense'\n",
    "    # intermediate_layer_model = Model(inputs=model.input,\n",
    "    #                                  outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "    # intermediate_layer_model.summary()\n",
    "    model.summary()\n",
    "\n",
    "    # intermediate_output = intermediate_layer_model.predict()\n",
    "    intermediate_output = y_pred\n",
    "    intermediate_output = pd.DataFrame(data=intermediate_output)\n",
    "\n",
    "    # val_data = intermediate_output[53000:]\n",
    "\n",
    "    submission_cnn = model.predict(np.float32(test['image']))\n",
    "\n",
    "    # intermediate_test_output = intermediate_layer_model.predict(test['image'])\n",
    "    intermediate_test_output = model.predict(np.float32(test['image']))\n",
    "    intermediate_test_output = pd.DataFrame(data=intermediate_test_output)\n",
    "\n",
    "    # xgbmodel = XGBClassifier(objective='multi:softprob', num_class=2)\n",
    "    # xgbmodel.fit(intermediate_output, train_label1)\n",
    "    # xgbmodel.score(val_data, val_label1)\n",
    "    #\n",
    "    # intermediate_layer_model.predict(X_test)\n",
    "    # submission_xgb = xgbmodel.predict(intermediate_test_output)\n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "    gnbmodel = GaussianNB().fit(intermediate_output, np.float32(train['label']))\n",
    "\n",
    "    submission_gnb = gnbmodel.predict(intermediate_test_output)\n",
    "    gnbmodel.score(np.float32(train['image'][valid_data.filenames]), valid_data.labels)\n",
    "\n",
    "    submission_cnn = submission_cnn.astype(int)\n",
    "\n",
    "    label = np.argmax(submission_cnn, 1)\n",
    "    id_ = np.arange(0, label.shape[0])\n",
    "    print(label)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
